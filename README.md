# ASL to Text Interpreter ğŸ¤Ÿ

Real-time ASL interpreter using OpenCV and TensorFlow/Keras for hand gesture recognition. Features custom hand tracking, image preprocessing, and gesture classification to translate American Sign Language into text output. Built with accessibility in mind.

> âš ï¸ **Note:** This project is currently under development.

## Features in Development

- Real-time hand gesture detection and tracking
- Image preprocessing pipeline
- Machine learning-based gesture classification
- Support for basic ASL gestures (only letters)

## Technical Stack

- Python 3.9+
- OpenCV (Computer Vision)
- TensorFlow/Keras (Machine Learning)
- cvzone (Hand Tracking)
- NumPy (Numerical Processing)

## Project Structure

```
asl-to-text/
â”‚
â”œâ”€â”€ Application.py 
â”œâ”€â”€ dataCollection.py
â”œâ”€â”€ data
â”œâ”€â”€ model/             
â”‚   â”œâ”€â”€ keras_model.h5  
â”‚   â””â”€â”€ labels.txt     
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt     
```

## Planned Features

- Text-to-speech functionality
- Expanded gesture vocabulary
- Improved model accuracy
- Support for continuous sentence formation
- GUI interface
- Multiple hand gesture support

## Development Status

This project is in active development. Current focus areas:
- Improving hand tracking accuracy
- Expanding the gesture recognition dataset
- Enhancing real-time performance
- Building out the core classification system

## Requirements

- Python 3.8 or higher
- Webcam or camera device
- Key packages: opencv-python, tensorflow, numpy, cvzone

---
*More documentation will be added as the project develops.*